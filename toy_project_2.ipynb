{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import lda\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('/home/ekim_reverse/PyCode/study/Python.study/online_news.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publisher</th>\n",
       "      <th>section</th>\n",
       "      <th>uid</th>\n",
       "      <th>분기</th>\n",
       "      <th>실질GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▲미래에셋증권=노희진 사외이사 중도 퇴임 ▲대한전선=보통주  4,717만주 8일 보...</td>\n",
       "      <td>2015-01-07T21:19:00.000000</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>economy</td>\n",
       "      <td>322784719026655424</td>\n",
       "      <td>2015Q1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘 개막한 세계 최대 가전전시회 CES에서는 무려 470여 개의 자동차 업체들이 ...</td>\n",
       "      <td>2015-01-07T20:41:00.000000</td>\n",
       "      <td>MBN</td>\n",
       "      <td>economy</td>\n",
       "      <td>322784719026655296</td>\n",
       "      <td>2015Q1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘CES 2015’에서 기술력 맞붙어\\n\\n“SUHD는 새로운 종의 TV 될 것”\\...</td>\n",
       "      <td>2015-01-07T19:55:00.000000</td>\n",
       "      <td>한겨레</td>\n",
       "      <td>tech</td>\n",
       "      <td>322785790314811520</td>\n",
       "      <td>2015Q1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>다음은 7일 장 마감 후 주요 종목 뉴스다.\\n\\n△동부제철(016380)=동부캐피...</td>\n",
       "      <td>2015-01-07T19:04:00.000000</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>economy</td>\n",
       "      <td>322784719018266816</td>\n",
       "      <td>2015Q1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아이에이는 안전한 자체 진단 기능을 갖는 반도체 소자 및 이를 이용한 자체 진단 방...</td>\n",
       "      <td>2015-01-07T19:02:00.000000</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>economy</td>\n",
       "      <td>322784719018266816</td>\n",
       "      <td>2015Q1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  ▲미래에셋증권=노희진 사외이사 중도 퇴임 ▲대한전선=보통주  4,717만주 8일 보...   \n",
       "1  오늘 개막한 세계 최대 가전전시회 CES에서는 무려 470여 개의 자동차 업체들이 ...   \n",
       "2  ‘CES 2015’에서 기술력 맞붙어\\n\\n“SUHD는 새로운 종의 TV 될 것”\\...   \n",
       "3  다음은 7일 장 마감 후 주요 종목 뉴스다.\\n\\n△동부제철(016380)=동부캐피...   \n",
       "4  아이에이는 안전한 자체 진단 기능을 갖는 반도체 소자 및 이를 이용한 자체 진단 방...   \n",
       "\n",
       "                 created_date publisher  section                 uid      분기  \\\n",
       "0  2015-01-07T21:19:00.000000      서울경제  economy  322784719026655424  2015Q1   \n",
       "1  2015-01-07T20:41:00.000000       MBN  economy  322784719026655296  2015Q1   \n",
       "2  2015-01-07T19:55:00.000000       한겨레     tech  322785790314811520  2015Q1   \n",
       "3  2015-01-07T19:04:00.000000      이데일리  economy  322784719018266816  2015Q1   \n",
       "4  2015-01-07T19:02:00.000000     머니투데이  economy  322784719018266816  2015Q1   \n",
       "\n",
       "   실질GDP  \n",
       "0    2.5  \n",
       "1    2.5  \n",
       "2    2.5  \n",
       "3    2.5  \n",
       "4    2.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pos() missing 1 required positional argument: 'phrase'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3e393df79867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: pos() missing 1 required positional argument: 'phrase'"
     ]
    }
   ],
   "source": [
    "x=Mecab.pos(data['content'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_n_b_a(x):\n",
    "    temp=t.pos(x)\n",
    "    \n",
    "    data=[]\n",
    "    \n",
    "    for line in temp:\n",
    "        if len(line[0])>1: #한글자 단어는 빼주는게 좋다. \n",
    "            if line[1] in ['Noun','Verb','Adjective']: # 명사, 동사, 형용사 라면 \n",
    "                data.append(line)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_text_n_b_a(data['content'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos=[]\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    tem=find_text_n_b_a(data['content'][i])\n",
    "    for list in tem: data_pos.append(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(data_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집된 단어의 횟수(len(ko.tokens))와 고유한 횟수(len(set(ko.tokens))) 확인 \n",
    "ko = nltk.Text(data_pos, name='data_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ko.tokens))        \n",
    "print(len(set(ko.tokens)))  \n",
    "ko.vocab()                        # 빈도수 분포도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = pd.read_excel('/home/ekim_reverse/PyCode/study/Python.study/stop_word.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = pd.read_excel('/home/ekim_reverse/PyCode/study/Python.study/data_count.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for w in data_count:\n",
    "    if w not in stop_words:\n",
    "        result.append(w)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(stop_words.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "vocab = data_count\n",
    "titles = data['content']\n",
    "\n",
    "model = lda.LDA(n_topics = 20, n_iter = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_\n",
    "n_top_words = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i,' '.joint(topic_words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
