{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://nycdatascience.com/blog/student-works/skinsmart-recommendation-system-skincare-products/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skincare'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c5c6c3ace44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskincare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSkincareItem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSkincareSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skincare'"
     ]
    }
   ],
   "source": [
    "from scrapy.spiders import Spider\n",
    "from scrapy.http import Request\n",
    "from scrapy.selector import Selector\n",
    "from skincare.items import SkincareItem\n",
    "\n",
    "class SkincareSpider(Spider):\n",
    "    name = \"skincare_spider\"\n",
    "    allowed_urls = ['http://www.totalbeauty.com/']\n",
    "\n",
    "    start_urls = [\"http://www.totalbeauty.com/reviews/face/page%s\" % page for page in xrange(1,1703)]\n",
    "\n",
    "    #parse main page to get a list of links for skincare products to parse\n",
    "    def parse(self,response):\n",
    "        products = response.xpath('//li[@class = \"clearfix\"]')\n",
    "        # first 8 products\n",
    "        for product in products:\n",
    "            item = SkincareItem()\n",
    "            item['Url'] = product.xpath('div[@class = \"prodName clearfix\"]/a[1]/@href').extract()[0]\n",
    "            item['Product'] = product.xpath('div[@class = \"prodName clearfix\"]/a[1]/text()').extract()[0]\n",
    "            item['Image'] = product.xpath('div[@class = \"prodImg\"]/a/img/@src').extract()[0]\n",
    "            \n",
    "            # Check that there is an actual review to scrape. If yes, then use review_parse function\n",
    "            try:\n",
    "            \titem['OverallScore'] = product.xpath('div[@class = \"prodName clearfix\"]/p/text()').extract()[0]\n",
    "            \titem['Rank'] = 0\n",
    "            \n",
    "            \t# send in request\n",
    "            \turl = 'http://www.totalbeauty.com'+ product.xpath('div[@class = \"prodName clearfix\"]/a[1]/@href').extract()[0]+\"/reviews?sort=5\"\n",
    "\n",
    "            \trequest = Request(url, callback = self.review_parse)\n",
    "            \trequest.meta['item'] = item\n",
    "            \tyield request\n",
    "              #Use specific parse function for products with no reviews\n",
    "            except IndexError:\n",
    "            \turl = 'http://www.totalbeauty.com'+ product.xpath('div[@class = \"prodName clearfix\"]/a[1]/@href').extract()[0]\n",
    "            \trequest = Request(url, callback = self.product_parse)\n",
    "            \trequest.meta['item'] = item\n",
    "            \tyield request\n",
    "\n",
    "        #last product\n",
    "        last = response.xpath('//li[@class = \"last clearfix\"]')\n",
    "        item = SkincareItem()\n",
    "        item['Url'] = last[0].xpath('div[@class = \"prodName clearfix\"]/a[1]/@href').extract()[0]\n",
    "        item['Product'] = last[0].xpath('div[@class = \"prodName clearfix\"]/a[1]/text()').extract()[0]\n",
    "\n",
    "        try:\n",
    "        \titem['OverallScore'] = last[0].xpath('div[@class = \"prodName clearfix\"]/p/text()').extract()[0]\n",
    "        \titem['Image'] = last[0].xpath('div[@class = \"prodImg\"]/a/img/@src').extract()[0]\n",
    "        \turl = 'http://www.totalbeauty.com/'+ last[0].xpath('div[@class = \"prodName clearfix\"]/a[1]/@href').extract()[0] + \"/reviews?sort=5\"\n",
    "        \trequest = Request(url, callback = self.review_parse)\n",
    "        \trequest.meta['item'] = item\n",
    "        \tyield request\n",
    "        except IndexError:\n",
    "        \turl = 'http://www.totalbeauty.com'+ product.xpath('div[@class = \"prodName clearfix\"]/a[1]/@href').extract()[0]\n",
    "        \trequest = Request(url, callback = self.product_parse)\n",
    "        \trequest.meta['item'] = item\n",
    "        \tyield request\n",
    "\n",
    "    #parsing function for the product page\n",
    "    def review_parse(self, response):\n",
    "        Category = response.xpath('//div[@class = \"rt_more_brands_heading\"]/div[2]/h2/text()').extract()[0]\n",
    "        Brand = response.xpath('//div[@class = \"rt_more_brands_heading\"]/div[2]/h2/text()').extract()[1]\n",
    "        item = response.meta['item']\n",
    "        item['Category'] = Category\n",
    "        item['Brand'] = Brand\n",
    "\n",
    "        #Extract featured reviews\n",
    "        features = response.xpath('//li[@class = \"memberReview featured\"]')\n",
    "        if features != []:\n",
    "            for feature in features:\n",
    "                item['Rank'] = item['Rank'] + 1 \n",
    "                item['UserRating'] = feature.xpath('div[@class = \"ratingStarSmall\"]/text()').extract()[0]\n",
    "                item['UserReviewTitle'] = feature.xpath('div[@class = \"userReview\"]/p/text()').extract()[0]\n",
    "                item['ReviewText'] = feature.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[1]/text()').extract()[0].strip()\n",
    "                # catch extra text\n",
    "                try:\n",
    "                    item['ReviewTextMore'] = feature.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[1]/span[2]/text()').extract()[0].strip()\n",
    "                except IndexError:\n",
    "                    item['ReviewTextMore'] = None\n",
    "                item['Featured']='1'\n",
    "                item['UserName']=feature.xpath('div[@class = \"userReview\"]/div[@class = \"myTbThumb\"]/div[@class = \"thumbrt\"]/cite[@class=\"reviewedBy\"]/a/text()').extract()[0]\n",
    "                item['Date'] = feature.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[2]/text()').extract()[0]\n",
    "                yield item\n",
    "\n",
    "        #Extract normal reviews\n",
    "        reviews = response.xpath('//li[@class = \"memberReview\"]')\n",
    "        for review in reviews:\n",
    "            item['Rank'] = item['Rank'] + 1 \n",
    "            item['UserRating'] = review.xpath('div[@class = \"ratingStarSmall\"]/text()').extract()[0]\n",
    "            item['UserReviewTitle'] = review.xpath('div[@class = \"userReview\"]/p/text()').extract()[0]\n",
    "            item['ReviewText'] = review.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[1]/text()').extract()[0].strip()\n",
    "            # catch extra text\n",
    "            try:\n",
    "                item['ReviewTextMore'] = review.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[1]/span[2]/text()').extract()[0].strip()\n",
    "            except IndexError:\n",
    "                item['ReviewTextMore'] = None\n",
    "\n",
    "            item['Featured']='0' \n",
    "            item['UserName']=review.xpath('div[@class = \"userReview\"]/div[@class = \"myTbThumb\"]/div[@class = \"thumbrt\"]/cite[@class=\"reviewedBy\"]/a/text()').extract()[0]   \n",
    "            item['Date'] = review.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[2]/text()').extract()[0]\n",
    "\n",
    "            yield item\n",
    "\n",
    "        # Extract last review of the page, which can be featured or just a normal review\n",
    "        reviews = response.xpath('//li[@class = \"memberReview last\"]')\n",
    "        if reviews == []:\n",
    "            reviews = response.xpath('//li[@class = \"memberReview featured last\"]')\n",
    "            item['Featured']='1'\n",
    "        else:\n",
    "            item['Featured']='0'    \n",
    "\n",
    "        review = reviews[0]\n",
    "        item['Rank'] = item['Rank'] + 1 \n",
    "        item['UserRating'] = review.xpath('div[@class = \"ratingStarSmall\"]/text()').extract()[0]\n",
    "        item['UserReviewTitle'] = review.xpath('div[@class = \"userReview\"]/p/text()').extract()[0]\n",
    "        item['ReviewText'] = review.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[1]/text()').extract()[0].strip()\n",
    "        # catch extra text\n",
    "        try:\n",
    "            item['ReviewTextMore'] = review.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[1]/span[2]/text()').extract()[0].strip()\n",
    "        except IndexError:\n",
    "            item['ReviewTextMore'] = None\n",
    "\n",
    "        item['UserName']=review.xpath('div[@class = \"userReview\"]/div[@class = \"myTbThumb\"]/div[@class = \"thumbrt\"]/cite[@class=\"reviewedBy\"]/a/text()').extract()[0]\n",
    "        item['Date'] = review.xpath('div[@class = \"userReview\"]/div[@class = \"reviewText\"]/span[2]/text()').extract()[0]\n",
    "\n",
    "        yield item\n",
    "\n",
    "\n",
    "        # yield request for next page of reviews\n",
    "        next_page_url = response.xpath('//*[@id=\"pagNext\"]/a/@href').extract_first()\n",
    "        # check that next page indeed exists\n",
    "        if next_page_url!=[]:\n",
    "            absolute_next_page_url = response.urljoin(next_page_url)\n",
    "            request = Request(absolute_next_page_url, callback = self.review_parse)\n",
    "            request.meta['item'] = item\n",
    "            yield request\n",
    "\n",
    "     # parsing function for products with no reviews\n",
    "    def product_parse(self, response):\n",
    "        Category = response.xpath('//div[@class = \"rt_more_brands_heading\"]/div[2]/h2/text()').extract()[0]\n",
    "        Brand = response.xpath('//div[@class = \"rt_more_brands_heading\"]/div[2]/h2/text()').extract()[1]\n",
    "        item = response.meta['item']\n",
    "        item['Category'] = Category\n",
    "        item['Brand'] = Brand\n",
    "        yield item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement skincare (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for skincare\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install skincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
